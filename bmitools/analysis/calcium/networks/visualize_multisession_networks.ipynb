{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aff08ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(180000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 180 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/.conda/envs/bmitools/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib tk\n",
    "%autosave 180\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "#%matplotlib inline\n",
    "\n",
    "import os\n",
    "from utils import *\n",
    "\n",
    "import os\n",
    "\n",
    "from utils_calcium import ProcessCalcium, get_reward_triggered_psth, plot_multi_session_psth_imshow, plot_psth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "044f5ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ***** USING non-merged binarization\n",
      "remove bad cells:  True\n",
      "...setting 2p parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:01<00:11,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ***** USING non-merged binarization\n",
      "remove bad cells:  True\n",
      "...setting 2p parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:03<00:10,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ***** USING non-merged binarization\n",
      "remove bad cells:  True\n",
      "...setting 2p parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:05<00:09,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ***** USING non-merged binarization\n",
      "remove bad cells:  True\n",
      "...setting 2p parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:07<00:07,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ***** USING non-merged binarization\n",
      "remove bad cells:  True\n",
      "...setting 2p parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [00:10<00:06,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ***** USING non-merged binarization\n",
      "remove bad cells:  True\n",
      "...setting 2p parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [00:12<00:04,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ***** USING non-merged binarization\n",
      "remove bad cells:  True\n",
      "...setting 2p parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [00:14<00:02,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ***** USING non-merged binarization\n",
      "remove bad cells:  True\n",
      "...setting 2p parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:16<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....DONE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "####################################################\n",
    "################## LOAD DATA #######################\n",
    "####################################################\n",
    "\n",
    "root_dir = '/media/cat/8TB/donato/bmi/'\n",
    "\n",
    "animal_ids = [\n",
    "    # M1 mice\n",
    "    \"DON-011733\",    # M1    - Processed\n",
    "    #\"DON-014618\",    # M1    - Processed\n",
    "    #'DON-014451',    # M1    - Processed\n",
    "    #'DON-014382',    # M1    - Processed\n",
    "    #'DON-014575',    # M1    - Processed\n",
    "    #'DON-014618',    # M1    - Processed\n",
    "    #'DON-015821',    # M1    - Processed\n",
    "    # 'DON-017923',   # M1    - Not Processed <has extra days at the end....\n",
    "    # 'DON-018129',   # M1    - Not Processed\n",
    "     #'DON-018130',   # M1    - Not Processed\n",
    "\n",
    "    # MAYBE MICE\n",
    "    # 'DON-013392'  <-- only last day was good, all others were at chance\n",
    "    # 'DON-015962'  <-- might be ok, rechedk it.\n",
    "\n",
    "    # CA3 mice\n",
    "    #\"DON-012502\",    # CA3    - spreadsheet is old - need reprocessing; ALSO Weird performance, may exclude\n",
    "    #\"DON-014266\",    # CA3   - Processed\n",
    "    #'DON-014371',    # CA3   - Processed\n",
    "    #'DON-015801',    # CA3   - Processed\n",
    "    #'DON-016658',    # CA3   - Processed\n",
    "    #\"DON-019683\",    # CA3   - Processed\n",
    "]\n",
    "#\n",
    "\n",
    "animal_id = animal_ids[0]\n",
    "\n",
    "#\n",
    "c = ProcessCalcium(root_dir,\n",
    "                    animal_id)\n",
    "\n",
    "# # \n",
    "c.remove_bad_cells = False\n",
    "c.use_non_merged = True\n",
    "\n",
    "#\n",
    "c.recompute_binarization = False  # IF TRue: must input correct params from bin notebooks\n",
    "c.dff_min = 0.05                  # min %DFF for [ca] burst to considered a spike (default 5%) overwrites percentile threshold parameter\n",
    "c.percentile_threshold = 0.99   # this is pretty fixed, we don't change it; we want [ca] bursts that are well outside the \"physics-caused\"noise\n",
    "c.maximum_std_of_signal = 0.25     # if std of signal is greater than this, then we have a noisy signal and we don't want to binarize it\n",
    "\n",
    "#\n",
    "c.save_figures = c.recompute_binarization\n",
    "c.load_sessions()\n",
    "\n",
    "#\n",
    "print (\"....DONE...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cf196a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load() takes exactly 1 positional argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 180\u001b[0m\n\u001b[1;32m    177\u001b[0m pcorr_thresh \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.99\u001b[39m\n\u001b[1;32m    178\u001b[0m use_median \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m \u001b[43mcompute_graph_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43manimal_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrecompute_graphs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpcorr_thresh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m                        \u001b[49m\u001b[43muse_median\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDONE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[12], line 138\u001b[0m, in \u001b[0;36mcompute_graph_metrics\u001b[0;34m(animal_id, recompute_graphs, pcorr_thresh, use_median)\u001b[0m\n\u001b[1;32m    135\u001b[0m     pr \u001b[38;5;241m=\u001b[39m d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpagerank\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m--> 138\u001b[0m     G \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m                                      \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgraph.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# add to lists\u001b[39;00m\n\u001b[1;32m    142\u001b[0m diameters\u001b[38;5;241m.\u001b[39mappend(diam)\n",
      "\u001b[0;31mTypeError\u001b[0m: load() takes exactly 1 positional argument (2 given)"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pickle\n",
    "import yaml\n",
    "\n",
    "\n",
    "#\n",
    "def compute_graph_metrics(animal_id, \n",
    "                          recompute_graphs=False, \n",
    "                          pcorr_thresh=0.99, \n",
    "                          use_median=False):\n",
    "    \n",
    "    # load yaml file and get session_ids field\n",
    "    fname_yaml = os.path.join(root_dir, \n",
    "                              animal_id, \n",
    "                              str(animal_id)+'.yaml')\n",
    "    \n",
    "    # load yaml file\n",
    "    d = yaml.load(open(fname_yaml), \n",
    "                  Loader=yaml.FullLoader)\n",
    "    \n",
    "    # get session ids\n",
    "    session_ids = d['session_ids']\n",
    "\n",
    "\n",
    "\n",
    "    # load all the pairwise distributions\n",
    "    diameters = []\n",
    "    clustering = []\n",
    "    aspl = []\n",
    "    degree = []\n",
    "    pagerank = []\n",
    "    ctr = 0\n",
    "    for session_id in session_ids[1:]:\n",
    "        \n",
    "        #\n",
    "        dir_main = os.path.join(root_dir, \n",
    "                                animal_id, \n",
    "                                str(session_id),\n",
    "                                'plane0',\n",
    "                                #'merged',\n",
    "                                'correlations')\n",
    "        \n",
    "        #\n",
    "        fname_out = os.path.join(dir_main, 'graph_metrics.npz')\n",
    "       #print (\"fname_out: \", fname_out)\n",
    "\n",
    "        if os.path.exists(fname_out)==False or recompute_graphs:\n",
    "\n",
    "            # load all the .npz files from dir_main\n",
    "            files = os.listdir(dir_main)\n",
    "            # delte all files that have \"graph\" in filename\n",
    "            files = [file for file in files if 'graph' not in file]\n",
    "            #print (\"# files: \", len(files))\n",
    "\n",
    "            # initialize connectivity matrix\n",
    "            cm = np.zeros((len(files), len(files)), 'float32')\n",
    "\n",
    "            #\n",
    "            for k in range(len(files)):\n",
    "\n",
    "                # load cell correlations\n",
    "                fname_pcorr = os.path.join(dir_main, files[k])\n",
    "                d = np.load(fname_pcorr, allow_pickle=True)\n",
    "                id = d['id']\n",
    "                zscore = d['z_score_pearson_corr']\n",
    "\n",
    "                # find which values are above threshold\n",
    "                idx = np.where(zscore>pcorr_thresh)[0]\n",
    "                cm[k,idx] = zscore[idx]\n",
    "\n",
    "                # this is a symmetric matrix\n",
    "                cm[idx,k] = zscore[idx]\n",
    "\n",
    "\n",
    "            # make a network graph from the cm matrix\n",
    "            G = nx.Graph(cm)\n",
    "\n",
    "            # remove self connections\n",
    "            G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "            # remove isolates\n",
    "            G.remove_nodes_from(list(nx.isolates(G)))\n",
    "\n",
    "            # find largest component in G\n",
    "            G_largest = G.subgraph(max(nx.connected_components(G), key=len))\n",
    "\n",
    "            # compute the diameter of G\n",
    "            diam = nx.diameter(G_largest)\n",
    "\n",
    "            # grab the clustering coefficient of G for all nodes\n",
    "            clust = nx.clustering(G_largest)\n",
    "            # compute the mean clustering coefficient from clust dict\n",
    "            if use_median:\n",
    "                clust = np.median(list(clust.values()))\n",
    "            else:\n",
    "                clust = np.mean(list(clust.values()))\n",
    "\n",
    "            # compute the average shortest path length\n",
    "            path_len = nx.average_shortest_path_length(G_largest)\n",
    "                \n",
    "            # compute the average degree\n",
    "            deg = nx.average_degree_connectivity(G_largest)\n",
    "            if use_median:\n",
    "                deg = np.median(list(deg.values()))\n",
    "            else:\n",
    "                deg = np.mean(list(deg.values()))\n",
    "\n",
    "            # compute the pagerank\n",
    "            pr = nx.pagerank(G_largest)\n",
    "            if use_median:\n",
    "                pr = np.median(list(pr.values()))\n",
    "            else:\n",
    "                pr = np.mean(list(pr.values()))\n",
    "\n",
    "            # Save the graph to a Pickle file\n",
    "            fname_pkl = os.path.join(dir_main, 'graph.pkl')\n",
    "            with open(fname_pkl, \"wb\") as f:\n",
    "                pickle.dump(G, f)\n",
    "        \n",
    "            np.savez(fname_out,\n",
    "                    diameters = diam,\n",
    "                    clustering = clust,\n",
    "                    aspl = path_len,\n",
    "                    degree = deg,\n",
    "                    pagerank = pr,\n",
    "                    pcorr_thresh = pcorr_thresh)\n",
    "\n",
    "\n",
    "        else:\n",
    "            d = np.load(fname_out, allow_pickle=True)\n",
    "            diam = d['diameters']\n",
    "            clust = d['clustering']\n",
    "            path_len = d['aspl']\n",
    "            deg = d['degree']\n",
    "            pr = d['pagerank']\n",
    "\n",
    "            #\n",
    "            G = pickle.load(open(os.path.join(os.path.split(fname_out)[0], \n",
    "                                              'graph.pkl')), \"rb\")\n",
    "\n",
    "        # add to lists\n",
    "        diameters.append(diam)\n",
    "        clustering.append(clust)\n",
    "        aspl.append(path_len)\n",
    "        degree.append(deg)\n",
    "        pagerank.append(pr)\n",
    "    \n",
    "        #\n",
    "        ctr+=1\n",
    "\n",
    "    # save master list\n",
    "    dir_out = os.path.join(root_dir, \n",
    "                           animal_id, \n",
    "                           'correlations')\n",
    "    if os.path.exists(dir_out)==False:\n",
    "        os.mkdir(dir_out)\n",
    "\n",
    "    # save master list\n",
    "    # load yaml file and get session_ids field\n",
    "    fname_out_animal = os.path.join(root_dir, \n",
    "                                    animal_id, \n",
    "                                    'correlations',\n",
    "                                    'graph_metrics.npz')\n",
    "    \n",
    "    np.savez(fname_out_animal,\n",
    "            pcorr_thresh = pcorr_thresh,\n",
    "            diameters = diameters,\n",
    "            clustering = clustering,\n",
    "            aspl = aspl,\n",
    "            degree = degree,\n",
    "            pagerank = pagerank\n",
    "            )\n",
    "\n",
    "\n",
    "#\n",
    "recompute_graphs = False\n",
    "pcorr_thresh = 0.99\n",
    "use_median = False\n",
    "\n",
    "compute_graph_metrics(animal_id,\n",
    "                        recompute_graphs,\n",
    "                        pcorr_thresh,\n",
    "                        use_median)\n",
    "\n",
    "\n",
    "print (\"DONE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a91304ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/.conda/envs/bmitools/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "def proc_data(ax, \n",
    "              data,\n",
    "              data_name,\n",
    "              clr,\n",
    "              text=None):\n",
    "\n",
    "    ax.set_title(data_name)\n",
    "    ax.plot(data,\n",
    "             linewidth=2,\n",
    "             color=clr)\n",
    "    # fit linear regression to the data\n",
    "    x = np.arange(len(data))\n",
    "    y = np.array(data)\n",
    "    idx = np.isfinite(y)\n",
    "    z = np.polyfit(x[idx], y[idx], 1)\n",
    "    p = np.poly1d(z)\n",
    "\n",
    "    rr,pp = scipy.stats.pearsonr(x,y)\n",
    "    #\n",
    "    ax.plot(x,p(x),\n",
    "             '--',\n",
    "             linewidth=2,\n",
    "             c=clr,\n",
    "             label = ('r='+str(np.round(rr,2))+' p='+str(np.round(pp,2))) if text is None else text\n",
    "             )\n",
    "    \n",
    "\n",
    "#\n",
    "clrs = ['blue','navy','lightblue','red','orange']\n",
    "\n",
    "# plot the distributions\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.suptitle(c.animal_id)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "for ctr, animal_id in enumerate(animal_ids):\n",
    "    fname = os.path.join(c.root_dir, \n",
    "                        animal_id,\n",
    "                        'correlations',\n",
    "                        'graph_metrics.npz')\n",
    "\n",
    "    #\n",
    "    data = np.load(fname, allow_pickle=True)\n",
    "    diameters = data['diameters']\n",
    "    clustering = data['clustering']\n",
    "    aspl = data['aspl']\n",
    "    degree = data['degree']\n",
    "    pagerank = data['pagerank']\n",
    "\n",
    "    # \n",
    "    data_array = [diameters, clustering, aspl, degree, pagerank]\n",
    "    data_names = ['Diameter', 'Clustering', 'Ave path len', 'Degree', 'Pagerank']\n",
    "\n",
    "    #\n",
    "    for k in range(5):\n",
    "        ax = plt.subplot(2,3,k+1)\n",
    "\n",
    "        proc_data(ax,\n",
    "                    data_array[k],\n",
    "                    data_names[k],\n",
    "                    clrs[ctr],\n",
    "                    text = animal_id if k==0 else None\n",
    "                    )\n",
    "        ax.legend()\n",
    "\n",
    "        # label xaxis with session starting with 'day0' and followed by 'bmiN' where n\n",
    "        ax.set_xlabel('Session #')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61ebc2a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2156899/189079872.py:17: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = matplotlib.cm.get_cmap('viridis')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/cat/8TB/donato/bmi/DON-019683/20240119/plane0/merged/F.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 27\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# find # of cells in recording\u001b[39;00m\n\u001b[1;32m     21\u001b[0m fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root_dir,\n\u001b[1;32m     22\u001b[0m                     animal_id,\n\u001b[1;32m     23\u001b[0m                     \u001b[38;5;28mstr\u001b[39m(session_ids[\u001b[38;5;241m0\u001b[39m]),\n\u001b[1;32m     24\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplane0\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     25\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmerged\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     26\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF.npy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m n_cells \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m# cells: \u001b[39m\u001b[38;5;124m\"\u001b[39m, n_cells)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/bmitools/lib/python3.8/site-packages/numpy/lib/npyio.py:405\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    403\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    406\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/cat/8TB/donato/bmi/DON-019683/20240119/plane0/merged/F.npy'"
     ]
    }
   ],
   "source": [
    "# plot the single cell correlations over time\n",
    "#\n",
    "\n",
    "animal_id = animal_ids[0]\n",
    "\n",
    "# load the yaml file to get session_ids\n",
    "fname_yaml = os.path.join(root_dir, \n",
    "                          animal_id, \n",
    "                          str(animal_id)+'.yaml')\n",
    "\n",
    "# load yaml file\n",
    "d = yaml.load(open(fname_yaml), \n",
    "              Loader=yaml.FullLoader)\n",
    "session_ids = d['session_ids']\n",
    "\n",
    "# make viridis map over len(session_ids)\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, len(session_ids))]\n",
    "\n",
    "# find # of cells in recording\n",
    "fname = os.path.join(root_dir,\n",
    "                    animal_id,\n",
    "                    str(session_ids[0]),\n",
    "                    'plane0',\n",
    "                    'merged',\n",
    "                    'F.npy')\n",
    "n_cells = np.load(fname).shape[0]\n",
    "print (\"# cells: \", n_cells)\n",
    "\n",
    "\n",
    "#\n",
    "cell_modes = []\n",
    "for cell_id in range(n_cells):\n",
    "\n",
    "    #\n",
    "    temp_mode = []\n",
    "    for ctr, session_id in enumerate(session_ids):\n",
    "        fname = os.path.join(root_dir,\n",
    "                            animal_id,\n",
    "                            str(session_id),\n",
    "                            'plane0',\n",
    "                           # 'merged',\n",
    "                            'correlations',\n",
    "                            str(cell_id)+'.npz')\n",
    "        \n",
    "        #\n",
    "        try:\n",
    "            dd = np.load(fname, allow_pickle=True)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        pcorr = dd['pearson_corr']\n",
    "\n",
    "        # remove nans\n",
    "        idx = np.isnan(pcorr)==False\n",
    "        pcorr = pcorr[idx]\n",
    "        # # get mode of pcor\n",
    "\n",
    "        # find 90th percentile of the pcorr distrib\n",
    "        try:\n",
    "            percentile = np.percentile(pcorr, 90)\n",
    "        except:\n",
    "            print (\"Error\", pcorr)\n",
    "\n",
    "        temp_mode.append(percentile)  \n",
    "\n",
    "        #break\n",
    "    #\n",
    "    cell_modes.append(temp_mode)\n",
    "\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d90407a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;28mlen\u001b[39m(cell_modes))\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;28mlen\u001b[39m(\u001b[43mcell_modes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# plot violion plots using seaborn\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#\n",
    "print (len(cell_modes))\n",
    "print (len(cell_modes[0]))\n",
    "\n",
    "\n",
    "# plot violion plots using seaborn\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "#\n",
    "n_sess = 9\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.violinplot(data=cell_modes[:n_sess], \n",
    "               #inner=\"quart\", \n",
    "               #palette=\"Set3\"\n",
    "               )\n",
    "\n",
    "#\n",
    "sess = ['day0', 'bmi1', 'bmi2', 'bmi3', 'bmi4', 'bmi5', 'bmi6', 'bmi7', 'bmi8']\n",
    "plt.xticks(np.arange(n_sess), sess[:n_sess], rotation=0)\n",
    "\n",
    "plt.ylabel('Median pairwise correlation')\n",
    "\n",
    "plt.suptitle(animal_id)\n",
    "\n",
    "#\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33656bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c9f393c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# cells:  712\n",
      " THIS IS A NON-MERGED DATASET\n",
      " ... can't do multi-session tracking... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2156899/2042534127.py:16: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = matplotlib.cm.get_cmap('viridis')\n"
     ]
    }
   ],
   "source": [
    "# plot the single cell correlations over time\n",
    "\n",
    "animal_id = 'DON-015801'\n",
    "\n",
    "# load the yaml file to get session_ids\n",
    "fname_yaml = os.path.join(root_dir, \n",
    "                          animal_id, \n",
    "                          str(animal_id)+'.yaml')\n",
    "\n",
    "# load yaml file\n",
    "d = yaml.load(open(fname_yaml), \n",
    "              Loader=yaml.FullLoader)\n",
    "session_ids = d['session_ids']\n",
    "\n",
    "# make viridis map over len(session_ids)\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "colors = [cmap(i) for i in np.linspace(0, 1, len(session_ids))]\n",
    "\n",
    "# find # of cells in recording\n",
    "fname = os.path.join(root_dir,\n",
    "                    animal_id,\n",
    "                    str(session_ids[0]),\n",
    "                    'plane0',\n",
    "                    'merged',\n",
    "                    'F.npy')\n",
    "n_cells = np.load(fname).shape[0]\n",
    "print (\"# cells: \", n_cells)\n",
    "\n",
    "if c.use_non_merged==True:\n",
    "    print (\" THIS IS A NON-MERGED DATASET\")\n",
    "    print (\" ... can't do multi-session tracking... \")\n",
    "else:\n",
    "\n",
    "\n",
    "    #\n",
    "    n_plots = 100\n",
    "    plt.figure(figsize=(15,15))\n",
    "    ctra =0\n",
    "    #cell_ids = np.arange()\n",
    "    cell_modes = []\n",
    "    for cell_id in range(n_cells):\n",
    "        ax = plt.subplot(int(np.sqrt(n_plots)),\n",
    "                        int(np.sqrt(n_plots)),\n",
    "                        ctra+1)\n",
    "\n",
    "        #\n",
    "        temp_mode = []\n",
    "        for ctr, session_id in enumerate(session_ids):\n",
    "            fname = os.path.join(root_dir,\n",
    "                                animal_id,\n",
    "                                str(session_id),\n",
    "                                'plane0',\n",
    "                                'merged',\n",
    "                                'correlations',\n",
    "                                str(cell_id)+'.npz')\n",
    "            \n",
    "            #\n",
    "            try:\n",
    "                dd = np.load(fname, allow_pickle=True)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            pcorr = dd['pearson_corr']\n",
    "            #print (pcorr)\n",
    "\n",
    "            # make a histogram\n",
    "            # y = np.histogram(pcorr, bins=np.arange(-0.1,0.25,0.01))   M1 mice\n",
    "            y = np.histogram(pcorr, bins=np.arange(-0.03,0.2,0.003))\n",
    "            xx = y[1][:-1]\n",
    "            yy = y[0]\n",
    "\n",
    "            # plot the histogram\n",
    "            plt.plot(xx,yy, \n",
    "                    color=colors[ctr],\n",
    "                    alpha=0.75\n",
    "                    #linewidth=2\n",
    "                    )\n",
    "            plt.yticks([])\n",
    "\n",
    "            plt.title(str(cell_id), fontsize=6)\n",
    "\n",
    "            # \n",
    "            if ctra<90:\n",
    "                plt.xticks([])\n",
    "            else:\n",
    "                # make tick size smaller\n",
    "                plt.xticks(fontsize=6)\n",
    "        #\n",
    "        ctra+=1\n",
    "\n",
    "        if ctra==n_plots:\n",
    "            plt.xlabel('Pearson correlation')\n",
    "            plt.ylabel('# pairs')\n",
    "            fname = os.path.join(root_dir,\n",
    "                                animal_id,\n",
    "                                'correlations',\n",
    "                                str(cell_id-n_plots+1)+'_correlations.png')\n",
    "            plt.savefig(fname,dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "            #\n",
    "            plt.figure(figsize=(15,15))\n",
    "            ctra=0\n",
    "\n",
    "\n",
    "    #\n",
    "    plt.xlabel('Pearson correlation')\n",
    "    plt.ylabel('# pairs')\n",
    "    fname = os.path.join(root_dir,\n",
    "                        animal_id,\n",
    "                        'correlations',\n",
    "                        str(cell_id-n_plots+1)+'_correlations.png')\n",
    "\n",
    "\n",
    "    plt.savefig(fname,dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48783c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4578927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c099b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3979279d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# files:  472\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Load data from specific animal / day\n",
    "animal_id = 'DON-015801'\n",
    "session_id = '20230615'\n",
    "\n",
    "dir_main = os.path.join(root_dir,\n",
    "                        animal_id,\n",
    "                        session_id,\n",
    "                        'plane0',\n",
    "                        'correlations')\n",
    "\n",
    "# find all.npz files in dir_main\n",
    "files = os.listdir(dir_main)\n",
    "files = [file for file in files if 'graph' not in file]\n",
    "print (\"# files: \", len(files))\n",
    "\n",
    "# make a connectivity matrix\n",
    "cm = np.zeros((len(files), len(files)), 'float32')\n",
    "\n",
    "#\n",
    "pcorr_thresh = 5\n",
    "for k in range(len(files)):\n",
    "        \n",
    "    # load cell correlations\n",
    "    fname_pcorr = os.path.join(dir_main, files[k])\n",
    "    d = np.load(fname_pcorr, allow_pickle=True)\n",
    "    id = d['id']\n",
    "    zscore = d['z_score_pearson_corr']\n",
    "    \n",
    "    # find which values are above threshold\n",
    "    idx = np.where(zscore>pcorr_thresh)[0]\n",
    "    cm[k,idx] = zscore[idx]\n",
    "    \n",
    "    # this is a symmetric matrix\n",
    "    cm[idx,k] = zscore[idx]\n",
    "\n",
    "    # make a boolean matrix\n",
    "    cm_bool = np.zeros((cm.shape),'bool')\n",
    "    cm_bool[cm>0]=1\n",
    "\n",
    "\n",
    "#\n",
    "plt.figure()\n",
    "plt.imshow(cm_bool,\n",
    "           vmin=0,\n",
    "           vmax=1,\n",
    "           cmap='binary')\n",
    "plt.ylim(0,cm_bool.shape[0])\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce4d147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14d395c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c531e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0329a0af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842e8835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a1138c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2af732e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "000f3c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(699, 90000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "d = np.load('/media/cat/8TB/donato/bmi/DON-014451/20230330/plane0/F.npy')\n",
    "print (d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d1ca6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing session:  20230130\n",
      " ... adding BLANK tone_state\n",
      " ... adding BLANK ensemble_state\n",
      " ... adding COPY OF post_reward_state as reward_state\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 54123/89951 [00:00<00:00, 270877.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... found rewarded trial at frame:  901  time:  30.033333333333335 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89951/89951 [00:00<00:00, 269949.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trials:  1 # of rewarded trials:  1\n",
      "reward_times and trials[idx][:,1] are not identical\n",
      "reward_times:  [ 8787 33064]\n",
      "trials[idx][:,1]:  [901]\n",
      "Exiting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "########### LOAD SPREADSHEETS AND METADATA #############\n",
    "########################################################\n",
    "\n",
    "# adds trial information; eventually should also add bursts etc...\n",
    "c.fix_spreadsheet()\n",
    "\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0ef26b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print (c.reward_state )\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(c.reward_state)\n",
    "plt.plot(c.post_reward_state)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac2aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "print (c.session_ids)\n",
    "c.fix_spreadsheet_missing_vals = True\n",
    "\n",
    "#\n",
    "print (c.session_types)\n",
    "c.load_spreadsheet_multi()\n",
    "\n",
    "# also save the res array in the same folder\n",
    "c.load_best_matches()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b9e0df1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# bouts to be zeroed out:  3\n"
     ]
    }
   ],
   "source": [
    "########################################################\n",
    "########## LOAD PAIRWISE CORRELATION DATA ##############\n",
    "########################################################\n",
    "# this is precomputed on the cluster \n",
    "#\n",
    "def zero_ca_artifacts(fname):\n",
    "    d = np.load(fname, \n",
    "                allow_pickle=True)\n",
    "\n",
    "    # load the upphase_bin\n",
    "    F_upphase = d['F_upphase']\n",
    "    F_detrended = d['F_detrended']\n",
    "    F_filtered = d['F_filtered']\n",
    " \n",
    "\n",
    "    # make mua\n",
    "    mua = np.sum(F_upphase,0)\n",
    "\n",
    "    thresh = 60\n",
    "    time_thresh = 30*2\n",
    "\n",
    "    # find periods where mua > thresh and that are longer than 10 frames\n",
    "    idx = np.where(mua>thresh)[0]\n",
    "\n",
    "    # find contiguous periods within idx and measure duration\n",
    "    bouts = []\n",
    "    start = idx[0]\n",
    "    #\n",
    "    for k in range(1,len(idx)-1,1):\n",
    "        if idx[k]==idx[k+1]-1:\n",
    "            continue\n",
    "        else:\n",
    "            end = idx[k]\n",
    "            if (end-start)>time_thresh:\n",
    "                bouts.append([start, end])\n",
    "            start = idx[k+1]\n",
    "\n",
    "    #\n",
    "    bouts = np.array(bouts)\n",
    "    print (\"# bouts to be zeroed out: \", bouts.shape[0])    \n",
    "\n",
    "    #\n",
    "    for bout in bouts:\n",
    "        F_upphase[:,bout[0]:bout[1]]=0\n",
    "        F_detrended[:,bout[0]:bout[1]]=0\n",
    "        F_filtered[:,bout[0]:bout[1]]=0\n",
    "\n",
    "    # save thsi files separately for each session\n",
    "    fname_out = os.path.join(os.path.split(fname)[0],\n",
    "                             'F_upphase.npy')\n",
    "    np.save(fname_out, F_upphase)\n",
    "\n",
    "    fname_out = os.path.join(os.path.split(fname)[0],\n",
    "                                'F_detrended.npy')\n",
    "    np.save(fname_out, F_detrended)\n",
    "\n",
    "    fname_out = os.path.join(os.path.split(fname)[0],\n",
    "                                'F_filtered.npy')\n",
    "    np.save(fname_out, F_filtered)\n",
    "\n",
    "    \n",
    "\n",
    "#\n",
    "fname = '/media/cat/8TB/donato/bmi/DON-015801/20230614/plane0/binarized_traces.npz'\n",
    "fname = '/media/cat/8TB/donato/bmi/DON-015801/20230614/plane0/merged/binarized_traces.npz'\n",
    "zero_ca_artifacts(fname)\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1819f479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94f5dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a483137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9b03df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136731fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41556ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "419d62bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c.cells_to_plot:  [270 321 223 196]\n",
      "session:  1  of 8 ,  reward times:  (33,)\n",
      "session:  2  of 8 ,  reward times:  (41,)\n",
      "session:  3  of 8 ,  reward times:  (33,)\n",
      "session:  4  of 8 ,  reward times:  (45,)\n",
      "session:  5  of 8 ,  reward times:  (64,)\n",
      "session:  6  of 8 ,  reward times:  (39,)\n",
      "session:  7  of 8 ,  reward times:  (56,)\n",
      "session:  8  of 8 ,  reward times:  (56,)\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "######## COMPUTE REWARD TRIGGERED RESPONSE OF ROIs ###########\n",
    "##############################################################\n",
    "# \n",
    "from utils_calcium import plot_psth_rois_only\n",
    "\n",
    "#\n",
    "def init_fig():\n",
    "    plt.figure(figsize=(20,12))\n",
    "    axes = []\n",
    "    for k in range(4):\n",
    "        ax=plt.subplot(2,2,k+1)\n",
    "        axes.append(ax) \n",
    "\n",
    "    return axes\n",
    "\n",
    "# \n",
    "window = 300\n",
    "start_cell=0\n",
    "show_random = True\n",
    "idx_cells = None\n",
    "smoothing = True\n",
    "plot_separately = False\n",
    "c.plot_rois_only = True\n",
    "c.cells_to_plot = c.best_matches\n",
    "c.cells_to_plot = np.random.choice(np.arange(c.sessions[0].F_filtered.shape[0]),\n",
    "                                   4,\n",
    "                                   replace=False)\n",
    "#\n",
    "print (\"c.cells_to_plot: \", c.cells_to_plot)\n",
    "#\n",
    "axes = init_fig()\n",
    "\n",
    "#\n",
    "for session_id in np.arange(1,9,1):\n",
    "\n",
    "    #\n",
    "    psths_avg, psths_shuffled_avg, idx_cells, n_bursts  = get_reward_triggered_psth(session_id, \n",
    "                                                                                    c,\n",
    "                                                                                    window,\n",
    "                                                                                    idx_cells)\n",
    "    #\n",
    "    plot_psth_rois_only(c,\n",
    "                        psths_avg,\n",
    "                        psths_shuffled_avg,\n",
    "                        session_id,\n",
    "                        axes,\n",
    "                        start_cell,\n",
    "                        idx_cells,\n",
    "                        show_random,\n",
    "                        smoothing,\n",
    "                        window\n",
    "                        )\n",
    "\n",
    "\n",
    "    # reset axes\n",
    "    if plot_separately:\n",
    "        #\n",
    "        plt.suptitle(c.animal_id+\" session: \"+str(session_id),fontsize=20)\n",
    "        #\n",
    "        plt.savefig('/home/cat/'+str(start_cell)+\"_session_\"+str(session_id)+'.png',dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        axes = init_fig()\n",
    "\n",
    "#\n",
    "plt.suptitle(c.animal_id+\" session: \"+str(session_id),fontsize=20)\n",
    "#\n",
    "plt.savefig('/home/cat/'+str(start_cell)+\"_session_\"+str(session_id)+'.png',dpi=300)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6f8ab619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session:  1  of 8 ,  reward times:  (33,)\n",
      "session:  2  of 8 ,  reward times:  (41,)\n",
      "session:  3  of 8 ,  reward times:  (33,)\n",
      "session:  4  of 8 ,  reward times:  (45,)\n",
      "session:  5  of 8 ,  reward times:  (64,)\n",
      "session:  6  of 8 ,  reward times:  (39,)\n",
      "session:  7  of 8 ,  reward times:  (56,)\n",
      "session:  8  of 8 ,  reward times:  (56,)\n",
      "(8, 540, 360)\n"
     ]
    }
   ],
   "source": [
    "##############################################################\n",
    "######## COMPUTE REWARD TRIGGERED RESPONSE OF CELLS ##########\n",
    "##############################################################\n",
    "window = 30*6\n",
    "psth_array = []\n",
    "idx_cells = None\n",
    "global_order = False\n",
    "session_ids = np.arange(1,len(c.session_ids),1)\n",
    "\n",
    "#\n",
    "n_bursts_array = []\n",
    "for session_id in session_ids:\n",
    "#for session_id in [1,7]:\n",
    "\n",
    "    #\n",
    "    psths_avg, psths_shuffled_avg, idx_cells, n_bursts  = get_reward_triggered_psth(session_id, \n",
    "                                                                                    c,\n",
    "                                                                                    window,\n",
    "                                                                                    idx_cells)\n",
    "    \n",
    "    #\n",
    "    n_bursts_array.append(n_bursts)\n",
    "    \n",
    "    #\n",
    "    psth_array.append(psths_avg[idx_cells[::-1]])\n",
    "\n",
    "    if global_order==False:\n",
    "        idx_cells = None\n",
    "\n",
    "#\n",
    "psth_array = np.array(psth_array)\n",
    "print (psth_array.shape)\n",
    "\n",
    "#\n",
    "vmax = 0.3\n",
    "sua = plot_multi_session_psth_imshow(c,\n",
    "                                session_ids,\n",
    "                                psth_array,\n",
    "                                window,\n",
    "                                n_bursts_array,\n",
    "                                vmax=vmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6388b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "572f0a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "low pass filter: 100%|██████████| 1/1 [00:00<00:00, 531.80it/s]\n",
      "model filter: remove bleaching or trends: 100%|██████████| 1/1 [00:00<00:00, 528.05it/s]\n",
      "fitting mode to physics:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cat/.conda/envs/bmi/lib/python3.8/site-packages/binarize2pcalcium/binarize2pcalcium.py:4026: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  y_mode = scipy.stats.mode(F_filtered2)[0]\n",
      "fitting mode to physics: 100%|██████████| 1/1 [00:00<00:00, 81.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumsum:  [4.63649033e-15 9.27561305e-15 1.39173696e-14 ... 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "binarizing continuous traces filtered fluorescence onphase: 100%|██████████| 1/1 [00:00<00:00, 79.64it/s]\n",
      "binarizing continuous traces filtered fluorescence upphase: 100%|██████████| 1/1 [00:00<00:00, 74.52it/s]\n",
      "low pass filter: 100%|██████████| 1/1 [00:00<00:00, 560.59it/s]\n",
      "model filter: remove bleaching or trends: 100%|██████████| 1/1 [00:00<00:00, 561.79it/s]\n",
      "fitting mode to physics: 100%|██████████| 1/1 [00:00<00:00, 76.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumsum:  [5.01316877e-10 1.00276836e-09 1.50435447e-09 ... 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "binarizing continuous traces filtered fluorescence onphase: 100%|██████████| 1/1 [00:00<00:00, 61.34it/s]\n",
      "binarizing continuous traces filtered fluorescence upphase: 100%|██████████| 1/1 [00:00<00:00, 51.25it/s]\n",
      "low pass filter: 100%|██████████| 1/1 [00:00<00:00, 592.58it/s]\n",
      "model filter: remove bleaching or trends: 100%|██████████| 1/1 [00:00<00:00, 561.79it/s]\n",
      "fitting mode to physics: 100%|██████████| 1/1 [00:00<00:00, 80.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumsum:  [2.27001954e-13 4.54110149e-13 6.81324632e-13 ... 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "binarizing continuous traces filtered fluorescence onphase: 100%|██████████| 1/1 [00:00<00:00, 89.88it/s]\n",
      "binarizing continuous traces filtered fluorescence upphase: 100%|██████████| 1/1 [00:00<00:00, 76.70it/s]\n",
      "low pass filter: 100%|██████████| 1/1 [00:00<00:00, 607.69it/s]\n",
      "model filter: remove bleaching or trends: 100%|██████████| 1/1 [00:00<00:00, 556.42it/s]\n",
      "fitting mode to physics: 100%|██████████| 1/1 [00:00<00:00, 72.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumsum:  [5.99037350e-12 1.19830454e-11 1.79780164e-11 ... 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "binarizing continuous traces filtered fluorescence onphase: 100%|██████████| 1/1 [00:00<00:00, 60.19it/s]\n",
      "binarizing continuous traces filtered fluorescence upphase: 100%|██████████| 1/1 [00:00<00:00, 50.29it/s]\n",
      "low pass filter: 100%|██████████| 1/1 [00:00<00:00, 585.31it/s]\n",
      "model filter: remove bleaching or trends: 100%|██████████| 1/1 [00:00<00:00, 555.32it/s]\n",
      "fitting mode to physics: 100%|██████████| 1/1 [00:00<00:00, 68.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumsum:  [3.64828491e-11 7.29779879e-11 1.09485420e-10 ... 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "binarizing continuous traces filtered fluorescence onphase: 100%|██████████| 1/1 [00:00<00:00, 61.93it/s]\n",
      "binarizing continuous traces filtered fluorescence upphase: 100%|██████████| 1/1 [00:00<00:00, 53.58it/s]\n",
      "low pass filter: 100%|██████████| 1/1 [00:00<00:00, 623.60it/s]\n",
      "model filter: remove bleaching or trends: 100%|██████████| 1/1 [00:00<00:00, 600.30it/s]\n",
      "fitting mode to physics: 100%|██████████| 1/1 [00:00<00:00, 76.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumsum:  [1.26496650e-17 2.53084175e-17 3.79762638e-17 ... 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "binarizing continuous traces filtered fluorescence onphase: 100%|██████████| 1/1 [00:00<00:00, 63.18it/s]\n",
      "binarizing continuous traces filtered fluorescence upphase: 100%|██████████| 1/1 [00:00<00:00, 56.17it/s]\n",
      "low pass filter: 100%|██████████| 1/1 [00:00<00:00, 595.87it/s]\n",
      "model filter: remove bleaching or trends: 100%|██████████| 1/1 [00:00<00:00, 520.26it/s]\n",
      "fitting mode to physics: 100%|██████████| 1/1 [00:00<00:00, 66.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cumsum:  [4.13738239e-19 8.27809700e-19 1.24221465e-18 ... 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "binarizing continuous traces filtered fluorescence onphase: 100%|██████████| 1/1 [00:00<00:00, 53.34it/s]\n",
      "binarizing continuous traces filtered fluorescence upphase: 100%|██████████| 1/1 [00:00<00:00, 40.86it/s]\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "#######################################\n",
    "#######################################\n",
    "\n",
    "# binarize the ensembel state    \n",
    "c.plotting = False\n",
    "c.scale_threshold = 0.05 #                 # we want to decrease the burst detection threshold manually - because the \n",
    "                                            # automatic threshold detection is too conservative \n",
    "c.dff_threshold = 0.1\n",
    "c.percentile_threshold = 0.999\n",
    "\n",
    "#\n",
    "#print (\"TODO: need to add the standaline binairzation code to the binarize2pcalcium package....\")\n",
    "#print (\" This is generally a good idea anyways for doing single time sieres extraction\")\n",
    "\n",
    "# right now only binarizing upphase - if want to do negative phase have to invert the signal\n",
    "c.sample_rate = 30\n",
    "c.binarize_ensemble_state_multi()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d025ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023ae69b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c181a8e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86d1cefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = np.load('/media/cat/8TB/donato/bmi/DON-011733/20230307/ensembles/ensembles_matches_bmi_to_suite2p.npz', allow_pickle=True)\n",
    "\n",
    "#\n",
    "plt.figure()\n",
    "ax=plt.subplot(411)\n",
    "#\n",
    "e1_0 = dd ['ensemble1_0_bmi']\n",
    "f0 = np.median(e1_0,0)\n",
    "e1_0 = (e1_0-f0)/f0\n",
    "e1_0_2p = dd['ensemble1_0_suite2p']\n",
    "plt.plot(e1_0, 'r')\n",
    "plt.plot(e1_0_2p, 'b')\n",
    "\n",
    "#\n",
    "ax=plt.subplot(412)\n",
    "e1_1 = dd ['ensemble1_1_bmi']\n",
    "f1 = np.median(e1_1,0)\n",
    "e1_1 = (e1_1-f1)/f1\n",
    "e1_1_2p = dd['ensemble1_1_suite2p']\n",
    "plt.plot(e1_1, 'r')\n",
    "plt.plot(e1_1_2p, 'b')\n",
    "\n",
    "#\n",
    "ax=plt.subplot(413)\n",
    "e2_0 = dd ['ensemble2_0_bmi']\n",
    "f2 = np.median(e2_0,0)\n",
    "e2_0 = (e2_0-f2)/f2\n",
    "e2_0_2p = dd['ensemble2_0_suite2p']\n",
    "plt.plot(e2_0, 'r')\n",
    "plt.plot(e2_0_2p, 'b')\n",
    "\n",
    "#\n",
    "ax=plt.subplot(414)\n",
    "e2_1 = dd ['ensemble2_1_bmi']\n",
    "f3 = np.median(e2_1,0)\n",
    "e2_1 = (e2_1-f3)/f3\n",
    "e2_1_2p = dd['ensemble2_1_suite2p']\n",
    "plt.plot(e2_1, 'r')\n",
    "plt.plot(e2_1_2p, 'b')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d623e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926f7654",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b502f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99976a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382188ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e291d36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "toc-autonumbering": false,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
